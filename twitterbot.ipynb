{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising the Model 1/2\n",
      "Initialising the Model 2/2\n",
      "Initialising done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialising the Model 1/2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "print(\"Initialising the Model 2/2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "print(\"Initialising done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_command(command):\n",
    "    new_user_input_ids = tokenizer.encode(command + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([new_user_input_ids], dim=-1)\n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    text = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 10:58:47.188839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-10 10:58:47.190490: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I want to know what you want for dinner.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take_command(\"What do you want for dinner?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:API created\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "consumer_key = \"4giejc8xz8LDWDZ0fxEFN49kl\"\n",
    "consumer_secret = \"UN5JaNJ05yTxrPCsEWlIOUZIHbFHwIwCjT32J9moAJhLTmFQFw\"\n",
    "access_token = \"1272256398005432322-r9A9pXdl0r6oKSu0ZPnfQxDsZO1ghj\"\n",
    "access_token_secret = \"4Pq9B2ULDqZeorjCzBcp6H7kXRqL6mHLXhhhbxU7LX7v8\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "except Exception as e:\n",
    "    logger.error(\"Error creating API\", exc_info=True)\n",
    "    raise e\n",
    "logger.info(\"API created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Answering to Nihal Puram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  what's your name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Waiting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb#ch0000006?line=28'>29</a>\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m60\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb#ch0000006?line=30'>31</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb#ch0000006?line=31'>32</a>\u001b[0m     main()\n",
      "\u001b[1;32m/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb Cell 6'\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb#ch0000006?line=26'>27</a>\u001b[0m since_id \u001b[39m=\u001b[39m check_mentions(api, [\u001b[39m\"\u001b[39m\u001b[39m#askme\u001b[39m\u001b[39m\"\u001b[39m], since_id)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb#ch0000006?line=27'>28</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mWaiting...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nihalpuram/Desktop/code/twitterbot/twitterbot.ipynb#ch0000006?line=28'>29</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m60\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def check_mentions(api, keywords, since_id):\n",
    "    logger.info(\"Retrieving mentions\")\n",
    "    new_since_id = since_id\n",
    "    for tweet in tweepy.Cursor(api.mentions_timeline,\n",
    "        since_id=since_id).items():\n",
    "        new_since_id = max(tweet.id, new_since_id)\n",
    "        if tweet.in_reply_to_status_id is not None:\n",
    "            continue\n",
    "        if any(keyword in tweet.text.lower() for keyword in keywords):\n",
    "            logger.info(f\"Answering to {tweet.user.name}\")\n",
    "\n",
    "            #if not tweet.user.following:\n",
    "                #tweet.user.follow()\n",
    "            command = tweet.text.lower()\n",
    "            command = command.replace('#askme','')\n",
    "            command = command.replace('@puramnihal','').strip()\n",
    "            print(command)\n",
    "            api.update_status(\n",
    "                status=take_command(command),\n",
    "                in_reply_to_status_id=tweet.id,\n",
    "            )\n",
    "    return new_since_id\n",
    "\n",
    "def main():\n",
    "    since_id = 1\n",
    "    while True:\n",
    "        since_id = check_mentions(api, [\"#askme\"], since_id)\n",
    "        logger.info(\"Waiting...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
